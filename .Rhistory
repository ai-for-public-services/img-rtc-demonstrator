loop_time_200m
10.33745/60
0.1722908+2.135462
dencies
# Load Dependencies
library(tidyverse)
library(terra)
library(sf)
library(sp)
################################################################################
# 1. Load in Data
################################################################################
rtc_2016 <- read_xlsx("data/raw/cambridgeshire-RTCs/RTC Location 2016.xlsx")
################################################################################
# 1. Load in Data
################################################################################
rtc_2016 <- readxl::read_xlsx("data/raw/cambridgeshire-RTCs/RTC Location 2016.xlsx")
head(rtc_2016)
rtc_2017 <- readxl::read_xlsx("data/raw/cambridgeshire-RTCs/RTC Location 2017_0.xlsx")
rtc_all <- st_read("data/raw/cambridgeshire-RTCs/Cambridgeshire RTCs 2017-August 2022.shp")
head(rtc)all
head(rtc_all)
# extent of the images i downloaded
total_extent = c(xmin = 541000, xmax = 551000, ymax = 254000, ymin = 264000)
################################################################################
# 2. Clean as necessary
################################################################################
# do the files contain the same information?
rtc_all %>% filter(str_detect("2017",Date)) %>% count()
str(rtc_all)
################################################################################
# 2. Clean as necessary
################################################################################
# do the files contain the same information?
rtc_all %>% filter(Date>=20170000 & Date<20180000) %>% count()
min(rtc_all$Date)
max(rtc_all$Date)
rtc_2017 %>% count()
names(rtc_2017)
names(rtc_all
)
names(rtc_2016)
rtc_all %>% st_geometry() %>% plot()
# crop to image area, how many data points are we really working with?
rtc_all <- rtc_all %>% st_filter(st_bbox(total_extent))
# crop to image area, how many data points are we really working with?
rtc_all <- rtc_all %>% st_filter(total_extent)
# crop to image area, how many data points are we really working with?
rtc_all <- rtc_all %>% st_intersection(st_bbox(total_extent))
# crop to image area, how many data points are we really working with?
rtc_all <- rtc_all %>% st_intersection(st_bbox(total_extent,crs = st_crs(rtc_all)))
st_bbox(total_extent,crs = st_crs(rtc_all))
st_as_sf(st_bbox(total_extent,crs = st_crs(rtc_all)))
st_as_sf(total_extent,crs = st_crs(rtc_all))
st_as_sfc(total_extent,crs = st_crs(rtc_all))
st_as_sfc(st_bbox(total_extent,crs = st_crs(rtc_all)))
# crop to image area, how many data points are we really working with?
rtc_all <- rtc_all %>% st_filter(st_as_sfc(st_bbox(total_extent,crs = st_crs(rtc_all))))
rtc_all %>% st_geometry() %>% plot()
################################################################################
# 2. Clean as necessary
################################################################################
# do the files contain the same information?
rtc_all %>% filter(Date>=20170000 & Date<20180000) %>% count() # 1463
# crop to image area, how many data points are we really working with?
rtc_2017 <- rtc_2017 %>% st_filter(st_as_sfc(st_bbox(total_extent,crs = st_crs(rtc_all))))
names(rtc_2016)
################################################################################
# 2. Clean as necessary
################################################################################
# turn dfs into sf objects
rtc_2016 <- st_as_sf(rtc_2016,coords = c("Easting","Northing"),crs=st_crs(rtc_all))
rtc_2016 %>% st_geometry() %>% plot()
rtc_2017 <- st_as_sf(rtc_2017,coords = c("Easting","Northing"),crs=st_crs(rtc_all))
rtc_2017 %>% st_geometry() %>% plot()
# do the files contain the same information?
rtc_all %>% filter(Date>=20170000 & Date<20180000) %>% count() # 1463
rtc_2017 %>% count() # 1427
# crop to image area, how many data points are we really working with?
rtc_all <- rtc_all %>% st_filter(st_as_sfc(st_bbox(total_extent,crs = st_crs(rtc_all))))
rtc_2017 <- rtc_2017 %>% st_filter(st_as_sfc(st_bbox(total_extent,crs = st_crs(rtc_all))))
rtc_2016 <- rtc_2016 %>% st_filter(st_as_sfc(st_bbox(total_extent,crs = st_crs(rtc_all))))
# do the files contain the same information?
rtc_all %>% filter(Date>=20170000 & Date<20180000) %>% count() # 1463
rtc_2017 %>% count() # 1427
unique(rtc_all$geometry)
unique(rtc_2016)
unique(rtc_2016$geometry)
unique(rtc_2017$geometry)
# visualize points
rtc_all %>% st_geometry() %>% plot()
rtc_2016 %>% st_geometry() %>% plot()
rtc_2017 %>% st_geometry() %>% plot()
# visualize points
rtc_all %>% st_geometry() %>% plot()
# more closely exmaine the two potential data files
rtc_all_2017 <- rtc_all %>% filter(Date>=20170000 & Date<20180000)
rtc_2017 %>% st_geometry() %>% plot()
rtc_all_2017 %>% st_geometry() %>% plot()
rtc_2017 %>% st_geometry() %>% plot()
rtc_all_2017 %>% st_geometry() %>% plot()
View(rtc_2017)
unique(rtc_2017$Police_ref)
table(rtc_2017$Police_ref %in% rtc_all_2017$Police_ref)
# Are all the police refs from the smaller file in the bigger one?
table(rtc_2017$Police_ref %in% rtc_all_2017$Police_ref) # all but one
# extract the 2020 datapoints
rtc_all_2020 <- rtc_all %>% filter(Date>=20200000 & Date<20210000)
# extract the 2020 datapoints
rtc_all %>% st_geometry() %>% plot()
# this claims to be all the data from 2017-2022
rtc_all <- st_read("data/raw/cambridgeshire-RTCs/Cambridgeshire RTCs 2017-August 2022.shp")
# extract the 2020 datapoints
rtc_all %>% st_geometry() %>% plot()
names(rtc_2016)
str(rtc_2016)
################################################################################
# 3. Create Some Descriptives
################################################################################
# start with the 2016 data
rtc_2016 <- rtc_2016 %>% mutate(
time_of_day = case_when(
Time<500~"Middle of Night",
Time>=500 & Time<1000 ~"Morning",
Time>=1000 & Time<1500 ~"Middle of Day",
Time>=1500 & Time<1900 ~"Afternoon",
Time>=1900 & Time<2300 ~"Evening",
Time>=2300~"Middle of Night",
)
)
table(rtc_2016$time_of_day)
################################################################################
# 3. Create Some Descriptives
################################################################################
# start with the 2016 data
rtc_2016 <- rtc_2016 %>% mutate(
time_of_day = case_when(
Time<500~"Night",
Time>=500 & Time<1000 ~"Morning",
Time>=1000 & Time<1500 ~"Middle of Day",
Time>=1500 & Time<2000 ~"Afternoon/Evening",
Time>=2000 ~"Night",
)
)
table(rtc_2016$time_of_day)
table(rtc_2016$Severity)
table(rtc_2016$Road_Class)
table(rtc_2016$`Junction Detail`)
table(rtc_2016$Light)
table(rtc_2016$Light,rtc_2016$time_of_day)
table(rtc_2016$Weather)
table(rtc_2016$Surface)
table(rtc_2016$Speed_limit)
table(rtc_2016$Cycle)
table(rtc_2016$Ped)
table(rtc_2016$Number_Vehicles)
names(rtc_2016)
rtc_2016 <- rtc_2016 %>% mutate(
time_of_day = case_when(
Time<500~"Night",
Time>=500 & Time<1000 ~"Morning",
Time>=1000 & Time<1500 ~"Middle of Day",
Time>=1500 & Time<2000 ~"Afternoon/Evening",
Time>=2000 ~"Night"),
surface=if_else(Surface=="Dry","dry","wet"),
cycle=if_else(Cycle=="Y",1,0),
pedestrian=if_else(Ped=="Y",1,0)
) %>% select(time_of_day,surface,cycle,pedestrian,Severity,Road_Class,Light,Speed_limit,Number_Vehicles)
rtc_2016
rtc_2016 <- rtc_2016 %>% janitor::clean_names()
install.packages("janitor")
rtc_2016 <- rtc_2016 %>% janitor::clean_names()
rtc_2016
242/383
library(ggplot2)
################################################################################
# 4. Generate Some Descriptives
################################################################################
rtc_2016 %>% ggplot(aes(time_of_day)) +
geom_bar(stat='count', width=.5)
################################################################################
# 4. Generate Some Descriptives
################################################################################
rtc_2016 %>% ggplot(aes(time_of_day)) +
geom_bar(stat='count', width=.5)  +
geom_text(color="white", size=2)
################################################################################
# 4. Generate Some Descriptives
################################################################################
rtc_2016 %>% ggplot(aes(time_of_day)) +
geom_bar(stat='count', width=.5)  +
geom_text(stat='count', aes(label=..count..), vjust=-1)
names(rtc_2016)
rtc_2016 %>% ggplot(aes(surface)) +
geom_bar(stat='count', width=.5)  +
geom_text(stat='count', aes(label=..count..), vjust=-1)
rtc_2016 %>% ggplot(aes(cycle)) +
geom_bar(stat='count', width=.5)  +
geom_text(stat='count', aes(label=..count..), vjust=-1)
rtc_2016 %>% ggplot(aes(cycle)) +
geom_bar(stat='identity', width=.5)
rtc_2016 %>% ggplot(aes(y=cycle)) +
geom_bar(stat='count', width=.5)
rtc_2016 %>% ggplot(aes(x=1, y=cycle)) +
geom_bar(stat='count', width=.5)
rtc_2016 %>% ggplot(aes( y=cycle)) +
geom_bar(stat='identity', width=.5)
rtc_2016 %>% ggplot(aes(x=1, y=cycle)) +
geom_bar(stat='identity', width=.5)
rtc_2016 %>% ggplot(aes(x=1, y=cycle,fill=cycle)) +
geom_bar(stat='identity', width=.5)
rtc_2016 %>% ggplot(aes(x=1, y=cycle,fill=as.factor(cycle))) +
geom_bar(stat='identity', width=.5)
rtc_2016 %>% ggplot(aes(cycle)) +
geom_bar(stat='count', width=.5)  +
geom_text(stat='count', aes(label=..count..), vjust=-1)
rtc_2016 %>% ggplot(aes(road_class)) +
geom_bar(stat='count', width=.5)  +
geom_text(stat='count', aes(label=..count..), vjust=-1)
chisq.test(table(rtc_2016$time_of_day))
names(rtc_all_2017)
View(rtc_all_2017)
table(rtc_all_2017$Veh_ref)
table(rtc_all_2017$Severity)
table(rtc_all_2017$Road_cond)
table(rtc_all_2017$Visibility)
table(rtc_2016$light)
table(rtc_all_2017$Pedestrian)
table(rtc_all_2017$Pedestrian,useNA = "ifany")
table(rtc_all_2017$Cycles,useNA = "ifany")
table(rtc_all_2017$Time,useNA = "ifany")
install.packages("stats19")
crashes = stats19::get_stats19(year = 2017, type = "accident")
names(crases)
names(crashes)
head(crashes)
# Load Dependencies
library(tidyverse)
library(terra)
library(sf)
library(sp)
total_extent=c(xmin = 541000, xmax = 551000, ymax = 254000, ymin = 264000)
View(crashes)
# this claims to be all the data from 2017-2022
rtc_all <- st_read("data/raw/cambridgeshire-RTCs/Cambridgeshire RTCs 2017-August 2022.shp")
rtc_2017 <- st_as_sf(crashes,coords = c("location_easting_osgr","location_northing_osgr"),crs=st_crs(rtc_all))
table(is.na(crashes$location_easting_osgr))
table(is.na(crashes$location_northing_osgr))
crashes <- crashes %>% dplyr::filter(is.na(location_easting_osgr)==FALSE)
rtc_2017 <- st_as_sf(crashes,coords = c("location_easting_osgr","location_northing_osgr"),crs=st_crs(rtc_all))
rtc_all <- rtc_all %>% st_filter(st_as_sfc(st_bbox(total_extent,crs = st_crs(rtc_all))))
rtc_2017 <- rtc_2017 %>% st_filter(st_as_sfc(st_bbox(total_extent,crs = st_crs(rtc_all))))
rtc_all_2017 <- rtc_all %>% filter(Date>=20170000 & Date<20180000)
vehicles <- stats19::get_stats19(year = 2017, type = "vehicle")
names(vehicles)
View(vehicles)
View(crashes)
sum(unique(vehicles$accident_index))
length(unique(vehicles$accident_index))
length(unique(crashes$accident_index))
# Load Dependencies
library(tidyverse)
library(terra)
library(sf)
library(sp)
# create a function to select points from the roads file
generate_sample_ids <- function(file_name="data/raw/Download_2087242/open-map-local_4707745/TL_Road.shp",
point_density=1/100,
total_extent=c(xmin = 541000, xmax = 551000, ymax = 254000, ymin = 264000)){
# read in the roads shapefile, note that TL correspondonds to the area with Cambridge
roads <- read_sf(file_name)
# will experiment with the OSM road shapefile as well as the OS roads file
# crop roads to the extent of my images
roads <- st_crop(roads,st_bbox(total_extent))
sampled_points <- st_line_sample(roads, density = point_density) # one point every 25 m
sampled_points <- st_cast(sampled_points, "POINT") # cast to point
# 5,935 roads, one point every 10m gives 62,425 points
# 5,935 roads, one point every 25m gives 24,961 points
# 5,935 roads, one point every 50m gives 12,459 points
# 5,935 roads, one point every 100m gives 6,145 points
}
sampled_points <- generate_sample_ids(file_name="data/raw/Download_2087242/open-map-local_4707745/TL_Road.shp",
point_density=1/100,
total_extent=c(xmin = 541000, xmax = 551000, ymax = 254000, ymin = 264000))
sample_150m_buffer <- st_buffer(sampled_points, 150, nQuadSegs = 1,endCapStyle = "SQUARE")
################################################################################
# 4. identify which image(s) are included within each buffer
################################################################################
# make into a spatvector to use terra
sample_150m_buffer<- vect(sample_150m_buffer)
#for each image see which of the polygon intersect the img
imagelist <- list.files("data/raw/cambridge-rgb/getmapping-rgb-25cm-2016_4700173/tl/") %>% Filter(function(x) {str_detect(x,"jpg")}, .)
imagelist <- unlist(lapply(imagelist, function(i){paste0(
"C:/Users/jfrancis/OneDrive - The Alan Turing Institute/Documents - AI for Government/6-Technical Projects/satellite-image-demonstrator/sat-img-demonstrator/data/raw/cambridge-rgb/getmapping-rgb-25cm-2016_4700173/tl/",i)}))
allrasters <- lapply(imagelist, terra::rast)
sample_150m_buffer <- st_buffer(sampled_points, 150, nQuadSegs = 1,endCapStyle = "SQUARE")
################################################################################
# 4. identify which image(s) are included within each buffer
################################################################################
# make into a spatvector to use terra
vect_150m_buffer<- vect(sample_150m_buffer)
point_to_img_150m <- data.frame(point_id=1:6145,st_coordinates(sampled_points))
# for each image, what polygon fall within them
for(i in 1:length(allrasters)){
a <- terra::is.related(vect_150m_buffer,allrasters[[i]],"intersects")
a <- list(a)
names(a)<- paste0("img_",i)
point_to_img_200m <- bind_cols(point_to_img_150m,a)
}
point_to_img_150m %>% select(-point_id,-X,-Y) %>% rowSums() %>% table()
sampled_points <- generate_sample_ids(file_name="data/raw/Download_2087242/open-map-local_4707745/TL_Road.shp",
point_density=1/100,
total_extent=c(xmin = 541000, xmax = 551000, ymax = 254000, ymin = 264000))
sample_150m_buffer <- st_buffer(sampled_points, 150, nQuadSegs = 1,endCapStyle = "SQUARE")
################################################################################
# 4. identify which image(s) are included within each buffer
################################################################################
# make into a spatvector to use terra
vect_150m_buffer<- vect(sample_150m_buffer)
#for each image see which of the polygon intersect the img
imagelist <- list.files("data/raw/cambridge-rgb/getmapping-rgb-25cm-2016_4700173/tl/") %>% Filter(function(x) {str_detect(x,"jpg")}, .)
imagelist <- unlist(lapply(imagelist, function(i){paste0(
"C:/Users/jfrancis/OneDrive - The Alan Turing Institute/Documents - AI for Government/6-Technical Projects/satellite-image-demonstrator/sat-img-demonstrator/data/raw/cambridge-rgb/getmapping-rgb-25cm-2016_4700173/tl/",i)}))
allrasters <- lapply(imagelist, terra::rast)
point_to_img_150m <- data.frame(point_id=1:6145,st_coordinates(sampled_points))
# for each image, what polygon fall within them
for(i in 1:length(allrasters)){
a <- terra::is.related(vect_150m_buffer,allrasters[[i]],"intersects")
a <- list(a)
names(a)<- paste0("img_",i)
point_to_img_150m <- bind_cols(point_to_img_150m,a)
}
point_to_img_150m %>% select(-point_id,-X,-Y) %>% rowSums() %>% table()
create_road_patch <- function(road_point_id=1, # id (row number) of centroid in point file
point_to_img_file=point_to_img_file, # file connecting centroids to rasters
buffer_size=buffer_size, # size of squares that have already been made
image_resolution=.25,
buffer_file=buffer_file,
save_location="data/processed/",
allrasters=allrasters # list of all raster files
){
temp_row <- point_to_img_file %>% filter(point_id %in% road_point_id) %>% select(-point_id,-X,-Y)
if(temp_row  %>% rowSums() <1 ){
# Skip if point doesn't overlap an image
return(paste0("Road segment for image ", road_point_id," not within saved aerial images."))
}
temp_row <- temp_row %>% select(where(~ . > 0))
img_list <- as.numeric(gsub("img_","",names(temp_row)))
# read in all of the images necessary for the given point
merge_list = list()
temp_buffer <- buffer_file[road_point_id]
for(d in 1:length(img_list)){
temp_img <- allrasters[[img_list[[d]]]]
temp_img <- crop(temp_img, temp_buffer)
merge_list <- append(merge_list, list(temp_img))
}
# if only one image things are super easy, just crop the image to the pointid of the buffer
if(length(img_list)==1){
final_temp_img <- merge_list[[1]]
}
# if multiple images, merge all of them together, and crop the larger image to the pointid of the buffer
if(length(img_list)>=1){
rsrc <- sprc(merge_list)
final_temp_img <- merge(rsrc)
}
dimension_check = buffer_size*(1/image_resolution)*2
# add a check to ensure that the patch is the correct size
if(dim(final_temp_img)[1]!=dimension_check | dim(final_temp_img)[2]!=dimension_check){
return(paste0("Road segment buffer for image ", road_point_id," only partially overlaps saved images."))
}
# Save images
invisible(writeRaster(final_temp_img, paste0(save_location,"cam-2017-",buffer_size,"m/cambdrige-",buffer_size,"m-point-",road_point_id,".tif"), overwrite=FALSE))
return(paste0("Image patch ",road_point_id, " saved successfully to ", save_location,"cambdrige-",buffer_size,"m-point-",road_point_id,".tif"))
}
start_time <- Sys.time()
for(i in 1:6145){
temp_message <- create_road_patch(
road_point_id=i, # id (row number) of centroid in point file
point_to_img_file=point_to_img_150m, # file connecting centroids to rasters
buffer_size=150, # size of squares that have already been made
image_resolution=.25,
buffer_file=vect_150m_buffer,
save_location="data/processed/",
allrasters=allrasters # list of all raster files
)
print(temp_message)
}
start_time <- Sys.time()
for(i in 1:6145){
temp_message <- create_road_patch(
road_point_id=i, # id (row number) of centroid in point file
point_to_img_file=point_to_img_150m, # file connecting centroids to rasters
buffer_size=150, # size of squares that have already been made
image_resolution=.25,
buffer_file=vect_150m_buffer,
save_location="data/processed/",
allrasters=allrasters # list of all raster files
)
print(temp_message)
}
# Purpose: Clean RGB Images to be used in ML pipeline
# Author: John Francis
# Date Created: Oct. 20, 2022
# Load Dependencies
library(tidyverse)
library(terra)
library(sf)
library(sp)
################################################################################
#                          Data Cleaning Steps                                 #
################################################################################
################################################################################
# 1. Load in/Generate a clean road shapefile for the area of interest
################################################################################
# NOTE: I know my shapefiles and images are all in British National Gird.
# If this was not the case for other datasets/images additional steps around reprojecting
# either the images, the shapefiles, or both may need to be done.
# create a function to select points from the roads file
generate_sample_ids <- function(file_name="data/raw/Download_2087242/open-map-local_4707745/TL_Road.shp",
point_density=1/100,
total_extent=c(xmin = 541000, xmax = 551000, ymax = 254000, ymin = 264000)){
# read in the roads shapefile, note that TL correspondonds to the area with Cambridge
roads <- read_sf(file_name)
# will experiment with the OSM road shapefile as well as the OS roads file
# crop roads to the extent of my images
roads <- st_crop(roads,st_bbox(total_extent))
sampled_points <- st_line_sample(roads, density = point_density) # one point every 25 m
sampled_points <- st_cast(sampled_points, "POINT") # cast to point
# 5,935 roads, one point every 10m gives 62,425 points
# 5,935 roads, one point every 25m gives 24,961 points
# 5,935 roads, one point every 50m gives 12,459 points
# 5,935 roads, one point every 100m gives 6,145 points
}
sampled_points <- generate_sample_ids(file_name="data/raw/Download_2087242/open-map-local_4707745/TL_Road.shp",
point_density=1/100,
total_extent=c(xmin = 541000, xmax = 551000, ymax = 254000, ymin = 264000))
sample_100m_buffer <- st_buffer(sampled_points, 100, nQuadSegs = 1,endCapStyle = "SQUARE")
################################################################################
# 4. identify which image(s) are included within each buffer
################################################################################
# make into a spatvector to use terra
vect_100m_buffer<- vect(sample_100m_buffer)
#for each image see which of the polygon intersect the img
imagelist <- list.files("data/raw/cambridge-rgb/getmapping-rgb-25cm-2016_4700173/tl/") %>% Filter(function(x) {str_detect(x,"jpg")}, .)
imagelist <- unlist(lapply(imagelist, function(i){paste0(
"C:/Users/jfrancis/OneDrive - The Alan Turing Institute/Documents - AI for Government/6-Technical Projects/satellite-image-demonstrator/sat-img-demonstrator/data/raw/cambridge-rgb/getmapping-rgb-25cm-2016_4700173/tl/",i)}))
allrasters <- lapply(imagelist, terra::rast)
point_to_img_100m <- data.frame(point_id=1:6145,st_coordinates(sampled_points))
# for each image, what polygon fall within them
for(i in 1:length(allrasters)){
a <- terra::is.related(vect_100m_buffer,allrasters[[i]],"intersects")
a <- list(a)
names(a)<- paste0("img_",i)
point_to_img_100m <- bind_cols(point_to_img_100m,a)
}
point_to_img_100m %>% select(-point_id,-X,-Y) %>% rowSums() %>% table()
create_road_patch <- function(road_point_id=1, # id (row number) of centroid in point file
point_to_img_file=point_to_img_file, # file connecting centroids to rasters
buffer_size=buffer_size, # size of squares that have already been made
image_resolution=.25,
buffer_file=buffer_file,
save_location="data/processed/",
allrasters=allrasters # list of all raster files
){
temp_row <- point_to_img_file %>% filter(point_id %in% road_point_id) %>% select(-point_id,-X,-Y)
if(temp_row  %>% rowSums() <1 ){
# Skip if point doesn't overlap an image
return(paste0("Road segment for image ", road_point_id," not within saved aerial images."))
}
temp_row <- temp_row %>% select(where(~ . > 0))
img_list <- as.numeric(gsub("img_","",names(temp_row)))
# read in all of the images necessary for the given point
merge_list = list()
temp_buffer <- buffer_file[road_point_id]
for(d in 1:length(img_list)){
temp_img <- allrasters[[img_list[[d]]]]
temp_img <- crop(temp_img, temp_buffer)
merge_list <- append(merge_list, list(temp_img))
}
# if only one image things are super easy, just crop the image to the pointid of the buffer
if(length(img_list)==1){
final_temp_img <- merge_list[[1]]
}
# if multiple images, merge all of them together, and crop the larger image to the pointid of the buffer
if(length(img_list)>=1){
rsrc <- sprc(merge_list)
final_temp_img <- merge(rsrc)
}
dimension_check = buffer_size*(1/image_resolution)*2
# add a check to ensure that the patch is the correct size
if(dim(final_temp_img)[1]!=dimension_check | dim(final_temp_img)[2]!=dimension_check){
return(paste0("Road segment buffer for image ", road_point_id," only partially overlaps saved images."))
}
# Save images
invisible(writeRaster(final_temp_img, paste0(save_location,"cam-2017-",buffer_size,"m/cambdrige-",buffer_size,"m-point-",road_point_id,".tif"), overwrite=FALSE))
return(paste0("Image patch ",road_point_id, " saved successfully to ", save_location,"cambdrige-",buffer_size,"m-point-",road_point_id,".tif"))
}
start_time <- Sys.time()
for(i in 1:1500){
temp_message <- create_road_patch(
road_point_id=i, # id (row number) of centroid in point file
point_to_img_file=point_to_img_100m, # file connecting centroids to rasters
buffer_size=100, # size of squares that have already been made
image_resolution=.25,
buffer_file=vect_100m_buffer,
save_location="data/processed/",
allrasters=allrasters # list of all raster files
)
print(temp_message)
}
end_time <- Sys.time()
loop_time_100m <- end_time - start_time
